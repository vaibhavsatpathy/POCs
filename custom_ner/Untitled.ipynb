{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Keras version 2.3.0 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "import coremltools\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.lite.experimental.examples.lstm.rnn import bidirectional_dynamic_rnn\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "import keras\n",
    "from keras.models import Model,Sequential, Input, load_model\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'amount': 0, 'bill_type': 1, 'other': 2, 'payment_day': 3, 'payment_month': 4, 'payment_type': 5}\n"
     ]
    }
   ],
   "source": [
    "vocab=[]\n",
    "entities=[]\n",
    "\n",
    "with open('result_usbank_1.json') as json_file:\n",
    "    dataset = json.load(json_file)\n",
    "    for data in dataset:\n",
    "    \tsent=data['sentence']\n",
    "    \ttags=data['tags']\n",
    "    \tentities.extend(tags)\n",
    "    \tfor word in sent:\n",
    "    \t\tvocab.append(word)\n",
    "json_file.close()\n",
    "\n",
    "vocab=set(vocab)\n",
    "t=Tokenizer(num_words=len(vocab))\n",
    "t.fit_on_texts(vocab)\n",
    "tokens=t.word_index\n",
    "\n",
    "num_words=len(tokens)+1\n",
    "\n",
    "reverse_tokens = dict([(value, key) for key, value in tokens.items()])\n",
    "\n",
    "entities=set(entities)\n",
    "entities=sorted(entities)\n",
    "entities=list(entities)\n",
    "label_encoder=LabelEncoder()\n",
    "int_encoded=label_encoder.fit_transform(entities)\n",
    "label_cat_encoded=to_categorical(int_encoded,num_classes=len(entities))\n",
    "\n",
    "master={}\n",
    "for i in range(len(entities)):\n",
    "\t#master[entities[i]]=int_encoded[i]\n",
    "\tmaster[entities[i]]=i\n",
    "print(master)\n",
    "\n",
    "reverse_master = dict([(value, key) for key, value in master.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation(sent,tags,tokens,master):\n",
    "    dummy_x=[]\n",
    "    dummy_y=[]\n",
    "    for word,tag in zip(sent,tags):\n",
    "        dummy_x.append(tokens[word.lower()])\n",
    "        dummy_y.append(master[tag])\n",
    "    return dummy_x,dummy_y\n",
    "\n",
    "def pre_process(sent,tokens):\n",
    "    zero_tok=0.0\n",
    "    sent=sent.split(\" \")\n",
    "    dummy_in=[]\n",
    "    for word in sent:\n",
    "        if word.lower() not in tokens:\n",
    "            dummy_in.append(zero_tok)\n",
    "        else:\n",
    "            dummy_in.append(tokens[word.lower()])\n",
    "    return dummy_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length=20\n",
    "X=[]\n",
    "Y=[]\n",
    "with open('result_usbank_1.json') as json_file:\n",
    "    dataset = json.load(json_file)\n",
    "    for data in dataset:\n",
    "        sent=data['sentence']\n",
    "        tags=data['tags']\n",
    "        tokenized_x,encoded_y=preparation(sent,tags,tokens,master)\n",
    "        X.append(tokenized_x)\n",
    "        Y.append(encoded_y)\n",
    "\n",
    "X=pad_sequences(X,maxlen=max_length,padding='post',dtype=float)\n",
    "y=pad_sequences(Y,maxlen=max_length,padding='post')\n",
    "y = y.reshape(y.shape[0],y.shape[1])\n",
    "y = to_categorical(y,num_classes=len(master))\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=0.2)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 20, 32)            5408      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 20, 64)            16640     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20, 6)             390       \n",
      "=================================================================\n",
      "Total params: 22,438\n",
      "Trainable params: 22,438\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# # model_new = tf.keras.models.Sequential([\n",
    "# #   tf.keras.Input(shape=(X.shape[1],), name='input'),\n",
    "# #   tf.keras.layers.Embedding(input_dim=len(vocab)+1,output_dim=32,input_length=X.shape[1],trainable=True),\n",
    "# #   tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32,return_sequences=True)),\n",
    "# #   tf.keras.layers.Dense(len(entities),activation=tf.nn.softmax,name='output')\n",
    "# # ])\n",
    "\n",
    "input_layer=Input(shape=(X.shape[1],))\n",
    "model=Embedding(input_dim=len(vocab)+1,output_dim=32,input_length=X.shape[1])(input_layer)\n",
    "model = Bidirectional(LSTM(units = 32,return_sequences=True, recurrent_dropout=0.2)) (model)\n",
    "output_layer= Dense(len(master), activation=\"softmax\")(model)\n",
    "model_new = Model(input_layer,output_layer)\n",
    "\n",
    "model_new.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 1.6584 - accuracy: 0.5800\n",
      "Epoch 2/100\n",
      "360/360 [==============================] - 0s 508us/step - loss: 0.9663 - accuracy: 0.7433\n",
      "Epoch 3/100\n",
      "360/360 [==============================] - 0s 494us/step - loss: 0.6917 - accuracy: 0.8079\n",
      "Epoch 4/100\n",
      "360/360 [==============================] - 0s 584us/step - loss: 0.6171 - accuracy: 0.8263\n",
      "Epoch 5/100\n",
      "360/360 [==============================] - 0s 497us/step - loss: 0.5766 - accuracy: 0.8353\n",
      "Epoch 6/100\n",
      "360/360 [==============================] - 0s 493us/step - loss: 0.5469 - accuracy: 0.8379\n",
      "Epoch 7/100\n",
      "360/360 [==============================] - 0s 504us/step - loss: 0.5173 - accuracy: 0.8406\n",
      "Epoch 8/100\n",
      "360/360 [==============================] - 0s 465us/step - loss: 0.4812 - accuracy: 0.8422\n",
      "Epoch 9/100\n",
      "360/360 [==============================] - 0s 481us/step - loss: 0.4346 - accuracy: 0.8429\n",
      "Epoch 10/100\n",
      "360/360 [==============================] - 0s 548us/step - loss: 0.3781 - accuracy: 0.8526\n",
      "Epoch 11/100\n",
      "360/360 [==============================] - 0s 480us/step - loss: 0.3127 - accuracy: 0.8943\n",
      "Epoch 12/100\n",
      "360/360 [==============================] - 0s 498us/step - loss: 0.2543 - accuracy: 0.9212\n",
      "Epoch 13/100\n",
      "360/360 [==============================] - 0s 479us/step - loss: 0.2039 - accuracy: 0.9344\n",
      "Epoch 14/100\n",
      "360/360 [==============================] - 0s 483us/step - loss: 0.1598 - accuracy: 0.9601\n",
      "Epoch 15/100\n",
      "360/360 [==============================] - 0s 483us/step - loss: 0.1253 - accuracy: 0.9808\n",
      "Epoch 16/100\n",
      "360/360 [==============================] - 0s 490us/step - loss: 0.0976 - accuracy: 0.9901\n",
      "Epoch 17/100\n",
      "360/360 [==============================] - 0s 493us/step - loss: 0.0761 - accuracy: 0.9922\n",
      "Epoch 18/100\n",
      "360/360 [==============================] - 0s 490us/step - loss: 0.0587 - accuracy: 0.9949\n",
      "Epoch 19/100\n",
      "360/360 [==============================] - 0s 496us/step - loss: 0.0455 - accuracy: 0.9965\n",
      "Epoch 20/100\n",
      "360/360 [==============================] - 0s 526us/step - loss: 0.0382 - accuracy: 0.9971\n",
      "Epoch 21/100\n",
      "360/360 [==============================] - 0s 492us/step - loss: 0.0319 - accuracy: 0.9972\n",
      "Epoch 22/100\n",
      "360/360 [==============================] - 0s 492us/step - loss: 0.0277 - accuracy: 0.9971\n",
      "Epoch 23/100\n",
      "360/360 [==============================] - 0s 495us/step - loss: 0.0247 - accuracy: 0.9974\n",
      "Epoch 24/100\n",
      "360/360 [==============================] - 0s 554us/step - loss: 0.0217 - accuracy: 0.9974\n",
      "Epoch 25/100\n",
      "360/360 [==============================] - 0s 496us/step - loss: 0.0194 - accuracy: 0.9974\n",
      "Epoch 26/100\n",
      "360/360 [==============================] - 0s 490us/step - loss: 0.0178 - accuracy: 0.9979\n",
      "Epoch 27/100\n",
      "360/360 [==============================] - 0s 490us/step - loss: 0.0164 - accuracy: 0.9979\n",
      "Epoch 28/100\n",
      "360/360 [==============================] - 0s 511us/step - loss: 0.0158 - accuracy: 0.9979\n",
      "Epoch 29/100\n",
      "360/360 [==============================] - 0s 493us/step - loss: 0.0143 - accuracy: 0.9982\n",
      "Epoch 30/100\n",
      "360/360 [==============================] - 0s 499us/step - loss: 0.0136 - accuracy: 0.9981\n",
      "Epoch 31/100\n",
      "360/360 [==============================] - 0s 537us/step - loss: 0.0129 - accuracy: 0.9985\n",
      "Epoch 32/100\n",
      "360/360 [==============================] - 0s 555us/step - loss: 0.0120 - accuracy: 0.9986\n",
      "Epoch 33/100\n",
      "360/360 [==============================] - 0s 493us/step - loss: 0.0117 - accuracy: 0.9981\n",
      "Epoch 34/100\n",
      "360/360 [==============================] - 0s 492us/step - loss: 0.0108 - accuracy: 0.9990\n",
      "Epoch 35/100\n",
      "360/360 [==============================] - 0s 495us/step - loss: 0.0102 - accuracy: 0.9987\n",
      "Epoch 36/100\n",
      "360/360 [==============================] - 0s 499us/step - loss: 0.0100 - accuracy: 0.9986\n",
      "Epoch 37/100\n",
      "360/360 [==============================] - 0s 496us/step - loss: 0.0096 - accuracy: 0.9987\n",
      "Epoch 38/100\n",
      "360/360 [==============================] - 0s 507us/step - loss: 0.0097 - accuracy: 0.9987\n",
      "Epoch 39/100\n",
      "360/360 [==============================] - 0s 538us/step - loss: 0.0093 - accuracy: 0.9987\n",
      "Epoch 40/100\n",
      "360/360 [==============================] - 0s 513us/step - loss: 0.0086 - accuracy: 0.9990\n",
      "Epoch 41/100\n",
      "360/360 [==============================] - 0s 495us/step - loss: 0.0084 - accuracy: 0.9990\n",
      "Epoch 42/100\n",
      "360/360 [==============================] - 0s 480us/step - loss: 0.0085 - accuracy: 0.9989\n",
      "Epoch 43/100\n",
      "360/360 [==============================] - 0s 479us/step - loss: 0.0082 - accuracy: 0.9987\n",
      "Epoch 44/100\n",
      "360/360 [==============================] - 0s 510us/step - loss: 0.0079 - accuracy: 0.9990\n",
      "Epoch 45/100\n",
      "360/360 [==============================] - 0s 501us/step - loss: 0.0076 - accuracy: 0.9989\n",
      "Epoch 46/100\n",
      "360/360 [==============================] - 0s 494us/step - loss: 0.0074 - accuracy: 0.9990\n",
      "Epoch 47/100\n",
      "360/360 [==============================] - 0s 501us/step - loss: 0.0073 - accuracy: 0.9990\n",
      "Epoch 48/100\n",
      "360/360 [==============================] - 0s 497us/step - loss: 0.0070 - accuracy: 0.9990\n",
      "Epoch 49/100\n",
      "360/360 [==============================] - 0s 513us/step - loss: 0.0070 - accuracy: 0.9990\n",
      "Epoch 50/100\n",
      "360/360 [==============================] - 0s 505us/step - loss: 0.0069 - accuracy: 0.9990\n",
      "Epoch 51/100\n",
      "360/360 [==============================] - 0s 498us/step - loss: 0.0068 - accuracy: 0.9990\n",
      "Epoch 52/100\n",
      "360/360 [==============================] - 0s 525us/step - loss: 0.0067 - accuracy: 0.9990\n",
      "Epoch 53/100\n",
      "360/360 [==============================] - 0s 575us/step - loss: 0.0064 - accuracy: 0.9989\n",
      "Epoch 54/100\n",
      "360/360 [==============================] - 0s 522us/step - loss: 0.0065 - accuracy: 0.9990\n",
      "Epoch 55/100\n",
      "360/360 [==============================] - 0s 508us/step - loss: 0.0064 - accuracy: 0.9989\n",
      "Epoch 56/100\n",
      "360/360 [==============================] - 0s 505us/step - loss: 0.0065 - accuracy: 0.9990\n",
      "Epoch 57/100\n",
      "360/360 [==============================] - 0s 517us/step - loss: 0.0063 - accuracy: 0.9990\n",
      "Epoch 58/100\n",
      "360/360 [==============================] - 0s 520us/step - loss: 0.0061 - accuracy: 0.9990\n",
      "Epoch 59/100\n",
      "360/360 [==============================] - 0s 501us/step - loss: 0.0063 - accuracy: 0.9990\n",
      "Epoch 60/100\n",
      "360/360 [==============================] - 0s 511us/step - loss: 0.0061 - accuracy: 0.9990\n",
      "Epoch 61/100\n",
      "360/360 [==============================] - 0s 556us/step - loss: 0.0058 - accuracy: 0.9990\n",
      "Epoch 62/100\n",
      "360/360 [==============================] - 0s 575us/step - loss: 0.0059 - accuracy: 0.9990\n",
      "Epoch 63/100\n",
      "360/360 [==============================] - 0s 525us/step - loss: 0.0059 - accuracy: 0.9990\n",
      "Epoch 64/100\n",
      "360/360 [==============================] - 0s 517us/step - loss: 0.0057 - accuracy: 0.9990\n",
      "Epoch 65/100\n",
      "360/360 [==============================] - 0s 539us/step - loss: 0.0056 - accuracy: 0.9990\n",
      "Epoch 66/100\n",
      "360/360 [==============================] - 0s 507us/step - loss: 0.0055 - accuracy: 0.9990\n",
      "Epoch 67/100\n",
      "360/360 [==============================] - 0s 595us/step - loss: 0.0055 - accuracy: 0.9990\n",
      "Epoch 68/100\n",
      "360/360 [==============================] - 0s 510us/step - loss: 0.0055 - accuracy: 0.9990\n",
      "Epoch 69/100\n",
      "360/360 [==============================] - 0s 526us/step - loss: 0.0056 - accuracy: 0.9990\n",
      "Epoch 70/100\n",
      "360/360 [==============================] - 0s 506us/step - loss: 0.0055 - accuracy: 0.9990\n",
      "Epoch 71/100\n",
      "360/360 [==============================] - 0s 532us/step - loss: 0.0050 - accuracy: 0.9990\n",
      "Epoch 72/100\n",
      "360/360 [==============================] - 0s 510us/step - loss: 0.0055 - accuracy: 0.9990\n",
      "Epoch 73/100\n",
      "360/360 [==============================] - 0s 512us/step - loss: 0.0050 - accuracy: 0.9990\n",
      "Epoch 74/100\n",
      "360/360 [==============================] - 0s 525us/step - loss: 0.0052 - accuracy: 0.9990\n",
      "Epoch 75/100\n",
      "360/360 [==============================] - 0s 518us/step - loss: 0.0053 - accuracy: 0.9990\n",
      "Epoch 76/100\n",
      "360/360 [==============================] - 0s 532us/step - loss: 0.0052 - accuracy: 0.9990\n",
      "Epoch 77/100\n",
      "360/360 [==============================] - 0s 513us/step - loss: 0.0049 - accuracy: 0.9990\n",
      "Epoch 78/100\n",
      "360/360 [==============================] - 0s 593us/step - loss: 0.0051 - accuracy: 0.9990\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 0s 649us/step - loss: 0.0049 - accuracy: 0.9990\n",
      "Epoch 80/100\n",
      "360/360 [==============================] - 0s 827us/step - loss: 0.0050 - accuracy: 0.9990\n",
      "Epoch 81/100\n",
      "360/360 [==============================] - 0s 648us/step - loss: 0.0051 - accuracy: 0.9990\n",
      "Epoch 82/100\n",
      "360/360 [==============================] - 0s 573us/step - loss: 0.0048 - accuracy: 0.9990\n",
      "Epoch 83/100\n",
      "360/360 [==============================] - 0s 528us/step - loss: 0.0049 - accuracy: 0.9990\n",
      "Epoch 84/100\n",
      "360/360 [==============================] - 0s 512us/step - loss: 0.0049 - accuracy: 0.9990\n",
      "Epoch 85/100\n",
      "360/360 [==============================] - 0s 522us/step - loss: 0.0051 - accuracy: 0.9990\n",
      "Epoch 86/100\n",
      "360/360 [==============================] - 0s 568us/step - loss: 0.0047 - accuracy: 0.9990\n",
      "Epoch 87/100\n",
      "360/360 [==============================] - 0s 537us/step - loss: 0.0047 - accuracy: 0.9989\n",
      "Epoch 88/100\n",
      "360/360 [==============================] - 0s 570us/step - loss: 0.0047 - accuracy: 0.9990\n",
      "Epoch 89/100\n",
      "360/360 [==============================] - 0s 513us/step - loss: 0.0051 - accuracy: 0.9989\n",
      "Epoch 90/100\n",
      "360/360 [==============================] - 0s 621us/step - loss: 0.0046 - accuracy: 0.9990\n",
      "Epoch 91/100\n",
      "360/360 [==============================] - 0s 512us/step - loss: 0.0046 - accuracy: 0.9989\n",
      "Epoch 92/100\n",
      "360/360 [==============================] - 0s 514us/step - loss: 0.0046 - accuracy: 0.9990\n",
      "Epoch 93/100\n",
      "360/360 [==============================] - 0s 555us/step - loss: 0.0046 - accuracy: 0.9990\n",
      "Epoch 94/100\n",
      "360/360 [==============================] - 0s 549us/step - loss: 0.0045 - accuracy: 0.9990\n",
      "Epoch 95/100\n",
      "360/360 [==============================] - 0s 530us/step - loss: 0.0046 - accuracy: 0.9990\n",
      "Epoch 96/100\n",
      "360/360 [==============================] - 0s 519us/step - loss: 0.0044 - accuracy: 0.9990\n",
      "Epoch 97/100\n",
      "360/360 [==============================] - 0s 521us/step - loss: 0.0043 - accuracy: 0.9990\n",
      "Epoch 98/100\n",
      "360/360 [==============================] - 0s 525us/step - loss: 0.0044 - accuracy: 0.9990\n",
      "Epoch 99/100\n",
      "360/360 [==============================] - 0s 523us/step - loss: 0.0040 - accuracy: 0.9990\n",
      "Epoch 100/100\n",
      "360/360 [==============================] - 0s 526us/step - loss: 0.0042 - accuracy: 0.9990\n"
     ]
    }
   ],
   "source": [
    "train_x,test_x,train_y,test_y = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "history = model_new.fit(train_x,train_y,epochs=100,batch_size=16)\n",
    "model_new.save('custom_ner_usbank.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab/vocab_ner_usbank.json','w') as f:\n",
    "    json.dump(tokens,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 60. 116. 166.  12. 120.  87. 110.  82.  59.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.]]\n",
      "Pay -----> other\n",
      "the -----> other\n",
      "excel -----> bill_type\n",
      "bill -----> other\n",
      "using -----> other\n",
      "my -----> other\n",
      "savings -----> payment_type\n",
      "account -----> other\n",
      "tomorrow -----> payment_day\n"
     ]
    }
   ],
   "source": [
    "temp='Pay the excel bill using my savings account tomorrow'\n",
    "length=temp.split(\" \")\n",
    "tok_sent=pre_process(temp,tokens)\n",
    "for i in range(max_length):\n",
    "    if len(tok_sent)<max_length:\n",
    "        tok_sent.append(0.0)\n",
    "tok_sent=np.expand_dims(tok_sent,axis=0)\n",
    "print(tok_sent)\n",
    "result=model_new.predict(tok_sent)\n",
    "for i in range(len(length)):\n",
    "    ind=np.argmax(result[0][i])\n",
    "    print(length[i],\"----->\",reverse_master[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : input_1, <keras.engine.input_layer.InputLayer object at 0x1464559b0>\n",
      "1 : embedding_1, <keras.layers.embeddings.Embedding object at 0x146455a20>\n",
      "2 : bidirectional_1, <keras.layers.wrappers.Bidirectional object at 0x146432278>\n",
      "3 : dense_1, <keras.layers.core.Dense object at 0x146455c50>\n",
      "4 : dense_1__activation__, <keras.layers.core.Activation object at 0x14d90ca58>\n"
     ]
    }
   ],
   "source": [
    "ner_label=['Date','Drug','Duration','Quantity','other']\n",
    "ner_usbank=['amount','bill_type','other','payment_day','payment_month','payment_type']\n",
    "\n",
    "coreml_model = coremltools.converters.keras.convert('custom_ner_usbank.h5',class_labels = ner_usbank)\n",
    "coreml_model.save('models/custom_ner_usbank.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# tokens=[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]]\n",
    "# tokens=np.array(tokens,dtype=np.double)\n",
    "# tokens = tokens.reshape(20,1,1)\n",
    "token=[59,]\n",
    "token=np.array(token,dtype=np.double)\n",
    "token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bidirectional_1_c_out_rev': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'classLabel': 'payment_day',\n",
       " 'bidirectional_1_h_out': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'bidirectional_1_c_out': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'bidirectional_1_h_out_rev': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'output1': {'amount': 0.06237495318055153,\n",
       "  'bill_type': 0.05016864463686943,\n",
       "  'other': 0.038017503917217255,\n",
       "  'payment_day': 0.6281217336654663,\n",
       "  'payment_month': 0.145807147026062,\n",
       "  'payment_type': 0.07550998032093048}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coreml_model.predict({'input1':token})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
